{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa1d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARVIS TECH Internship Programme\n",
    "#September 2022\n",
    "\n",
    "#Pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a95415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.signal import filtfilt, butter, lfilter, medfilt\n",
    "from matplotlib import pyplot as plt \n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2772a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon(image, coordinates, facial_landmarks):\n",
    "    #returns the region in the frame as a polygon for the selected landmark points.\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    area = []\n",
    "    for i in coordinates:\n",
    "        pt1 = facial_landmarks.landmark[i]\n",
    "        x = int(pt1.x * width)\n",
    "        y = int(pt1.y * height)\n",
    "        area.append([x,y])\n",
    "        #cv2.circle(image, (x, y), 2, (100, 100, 0), -1)\n",
    "        #cv2.putText(image, str(i), (x, y), 0, 0.5, (0, 0, 0))\n",
    "        \n",
    "    area = np.array(area)\n",
    "    area = area.reshape((-1, 1, 2))\n",
    "    #cv2.polylines(image,[area],True,(0,255,255))\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d13153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(image, yanak_sag , yanak_sol, alin):\n",
    "    #this function extracts ROI areas and put them on a black background from the base image\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.drawContours(mask, [yanak_sag], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    cv2.drawContours(mask, [yanak_sol], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    cv2.drawContours(mask, [alin], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    output = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e2077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def green(image, area):\n",
    "    #function to find green channel averages of given image and ROI\n",
    "\n",
    "    mask_G = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.drawContours(mask_G, [area], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    mean = cv2.mean(image[:,:,1], mask=mask_G)\n",
    "    #print(f\"{txt}= {mean}\")\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2937a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_signal(green_mean, green_arr, n_frames):\n",
    "    #updates green channel array signal\n",
    "    \n",
    "    #if size of array is less than given limit, it appends the green channel mean to the signal array\n",
    "    if len(green_arr) < n_frames:\n",
    "        green_arr.append(green_mean)\n",
    "        \n",
    "    #else it keeps the size of the array constant by deleting an element from the beginning and appending an element to the end\n",
    "    else:\n",
    "        del green_arr[0]\n",
    "        green_arr.append(green_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3777a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nabiz_bul(mean_list, fps, hz_bottom, hz_top):\n",
    "    sampling_rate = fps\n",
    "    raw_signal = np.squeeze(mean_list) \n",
    "    normalized_signal = raw_signal - np.mean(raw_signal)\n",
    "    normalized_signal = normalized_signal / np.std(normalized_signal)\n",
    "    med_signal = medfilt(normalized_signal, 5)\n",
    "    nyq = 0.5 * sampling_rate\n",
    "    low = hz_bottom / nyq\n",
    "    high = hz_top / nyq\n",
    "\n",
    "    b, a = butter(3, [low, high], btype = 'band')\n",
    "    filtered_signal = lfilter(b, a, med_signal)\n",
    "    window = np.hamming(len(filtered_signal))\n",
    "    windowed_signal = filtered_signal * window\n",
    "    def nextpow(x):\n",
    "        return 2 ** math.ceil(math.log2(x))\n",
    "\n",
    "    NFFT = nextpow(len(windowed_signal) * sampling_rate)\n",
    "    freqDomain = np.fft.fft(windowed_signal, NFFT)\n",
    "    conj = np.conjugate(freqDomain)\n",
    "\n",
    "    powerSpectrum = np.multiply(freqDomain, conj) / NFFT\n",
    "    powerSpectrum = np.real(powerSpectrum)\n",
    "\n",
    "    freqInterestL = hz_bottom\n",
    "    freqInterestH = hz_top\n",
    "\n",
    "    freqs = np.linspace(0, sampling_rate, NFFT)\n",
    "    fRange = list()\n",
    "\n",
    "    for i in range(len(freqs)):\n",
    "        if freqs[i] < freqInterestH and freqs[i] > freqInterestL:\n",
    "            fRange.append(i + 1)\n",
    "\n",
    "    HRange = list()\n",
    "    for i in range(len(fRange)):\n",
    "        idx = 60 * freqs[fRange[i]]\n",
    "        HRange.append(idx)\n",
    "    max_x = HRange[powerSpectrum[fRange].argmax()]\n",
    "    return max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20118b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pulse(path = 0, plot_signal = False):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    #finds the fps of the video\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    else :\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "    # Face Mesh\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "    \n",
    "    #array to store green channel means of each frame   \n",
    "    green_arr = []\n",
    "    \n",
    "    #array to store pulse values   \n",
    "    nabiz = []\n",
    "\n",
    "\n",
    "    # Create figure and subplot\n",
    "    if plot_signal:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        \n",
    "    #frame counter\n",
    "    ctr = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if ret is not True:\n",
    "            break\n",
    "\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Facial landmarks\n",
    "        result = face_mesh.process(rgb_image)\n",
    "        \n",
    "        #mediapipe crashes in case it cannot find a face to detect therefore try/except blocks used here\n",
    "        try:\n",
    "\n",
    "            for facial_landmarks in result.multi_face_landmarks:\n",
    "                \n",
    "                #left cheek landmark points \n",
    "                yanak_sol_arr = [143, 123, 147, 213, 138, 135, 210, 202, 57, 92, 36, 101, 118, 31, 143]\n",
    "                yanak_sol = polygon(image, yanak_sol_arr, facial_landmarks)\n",
    "\n",
    "            for facial_landmarks in result.multi_face_landmarks:\n",
    "                \n",
    "                #right cheek landmark points \n",
    "                yanak_sag_arr = [372, 352, 376, 433, 367, 364, 430, 422, 287, 322, 266, 330, 347, 261, 372]\n",
    "                yanak_sag = polygon(image, yanak_sag_arr, facial_landmarks)\n",
    "\n",
    "            for facial_landmarks in result.multi_face_landmarks:\n",
    "\n",
    "                #forehead landmark points \n",
    "                alin_arr = [54, 103, 67, 109, 10, 338, 297, 332, 284, 298, 296, 9, 66, 68,]\n",
    "                alin = polygon(image, alin_arr, facial_landmarks)\n",
    "\n",
    "            #extracts ROI areas from the base image\n",
    "            image = extract_roi(image, yanak_sag , yanak_sol, alin)\n",
    "            \n",
    "            #the green channel average of each ROI areas\n",
    "            mean_yanak_sag = green(image, yanak_sag)[0]\n",
    "            mean_yanak_sol = green(image, yanak_sol)[0]\n",
    "            mean_alin = green(image, alin)[0]\n",
    "            \n",
    "            #mean green channel value of all ROI areas combined\n",
    "            mean_raw = (mean_yanak_sag + mean_yanak_sol + mean_alin)/3\n",
    "            \n",
    "            #updates green channel array\n",
    "            #the limit of the array is 10 seconds.\n",
    "            update_signal(mean_raw, green_arr, n_frames=fps*10)\n",
    "            \n",
    "            #if size of green_array channel is greater than 3 seconds of frame size\n",
    "            #Without the if block, it would try to find a pulse value for an array that was not large enough\n",
    "            #that would cause an error.\n",
    "            if len(green_arr) >= fps*3:\n",
    "                \n",
    "                #finds pulse from the green channel signal\n",
    "                nabiz.append(nabiz_bul(green_arr, fps=fps, hz_bottom=1.0, hz_top=2.75))\n",
    "                \n",
    "                #putting the last element of the pulse on the frame\n",
    "                #If a smoother transition between pulse values is desired, \n",
    "                #the average of the last 3 seconds pulse values can be putted on the frane.\n",
    "                cv2.putText(image,\"PULSE: \" + str(round(nabiz[-1])), (150, 30), font, 1, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "            # putting the FPS count on the frame\n",
    "            cv2.putText(image, \"FPS: \" + str(int(fps)), (7, 30), font, 1, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "            \n",
    "            #plotting the green array signal\n",
    "            if plot_signal:\n",
    "                if ctr % (fps/2) == 0:\n",
    "                    ax.cla()\n",
    "                    ax.plot(green_arr)\n",
    "                    display(fig)    \n",
    "                    clear_output(wait = True)\n",
    "\n",
    "        #if mediapipe cannot detects face it prints \"No Face Detected\" to the screen\n",
    "        except:\n",
    "            text = \"No Face Detected\"\n",
    "            coordinates = (128,128)\n",
    "            fontScale = 1\n",
    "            color = (255,0,255)\n",
    "            thickness = 2\n",
    "            blank = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "            image = cv2.putText(blank, text, coordinates, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"roi areas\", image)\n",
    "        \n",
    "        ctr += 1\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break   \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 0\n",
    "find_pulse(path=path, plot_signal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39904fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb087800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
